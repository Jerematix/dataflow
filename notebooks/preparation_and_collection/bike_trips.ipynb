{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastparquet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../../data/philadelphia_2016_raw.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 655058 entries, 0 to 655057\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   start_time          655058 non-null  object \n",
      " 1   end_time            655058 non-null  object \n",
      " 2   start_station_id    655048 non-null  float64\n",
      " 3   end_station_id      655058 non-null  int64  \n",
      " 4   bike_id             655058 non-null  int64  \n",
      " 5   user_type           655058 non-null  object \n",
      " 6   end_station_name    655058 non-null  object \n",
      " 7   start_station_name  655048 non-null  object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 40.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see from the df_raw.info(), that for start and end station id and name there are 10 missing rows, otherwise there aren't any, in addition the that start_station_id is a float when in reality it should be int, due to having no decimal place.\n",
    "Also the times are not formatted in the proper datetime format."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem\\AppData\\Local\\Temp\\ipykernel_19452\\943598606.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_station_id'] = df['start_station_id'].astype('int64')\n",
      "C:\\Users\\jerem\\AppData\\Local\\Temp\\ipykernel_19452\\943598606.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_time'] = pd.to_datetime(df['start_time'])\n",
      "C:\\Users\\jerem\\AppData\\Local\\Temp\\ipykernel_19452\\943598606.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['end_time'] = pd.to_datetime(df['end_time'])\n"
     ]
    }
   ],
   "source": [
    "#Only take the rows that are not na in name or id\n",
    "df = df_raw[df_raw['start_station_id'].notna() & df_raw['start_station_name'].notna()]\n",
    "df['start_station_id'] = df['start_station_id'].astype('int64')\n",
    "\n",
    "#Format to Datetime\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "df['end_time'] = pd.to_datetime(df['end_time'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 655048 entries, 0 to 655057\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   start_time          655048 non-null  datetime64[ns]\n",
      " 1   end_time            655048 non-null  datetime64[ns]\n",
      " 2   start_station_id    655048 non-null  int64         \n",
      " 3   end_station_id      655048 non-null  int64         \n",
      " 4   bike_id             655048 non-null  int64         \n",
      " 5   user_type           655048 non-null  object        \n",
      " 6   end_station_name    655048 non-null  object        \n",
      " 7   start_station_name  655048 non-null  object        \n",
      "dtypes: datetime64[ns](2), int64(3), object(3)\n",
      "memory usage: 45.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see now, that there are no null values and everything is formatted correctly"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest trip: -1 days +23:04:00\n",
      "Longest trip: 19 days 00:59:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem\\AppData\\Local\\Temp\\ipykernel_19452\\3132717644.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['duration'] = (df['end_time'] - df['start_time'])\n"
     ]
    }
   ],
   "source": [
    "df['duration'] = (df['end_time'] - df['start_time'])\n",
    "\n",
    "print(f\"Shortest trip: {df['duration'].min()}\")\n",
    "print(f\"Longest trip: {df['duration'].max()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# add new column duration and determine its minimum and maximum values\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "#Remove all the invalid times\n",
    "df = df[(df['duration'] <= pd.Timedelta(\"1d\")) & (df['duration'] >= pd.Timedelta(\"1m\")) | ((df['duration'] <= pd.Timedelta(\"5m\")) & (df['start_station_id'] == df['end_station_id']))]\n",
    "#Also Remove Station 3000 Called \"Virtual Station\" supposedly for Test Trips\n",
    "df = df[(df['start_station_id'] != 3000) & (df['end_station_id'] != 3000)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Indego30', 'Walk-up', 'IndegoFlex'], dtype=object)"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at different Types\n",
    "df['user_type'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv('../../data/stations.csv')\n",
    "del df_stations['name']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "df = df.merge(df_stations, left_on='start_station_id', right_on='id')\n",
    "del df['id']\n",
    "df['start_lat'] = df['lat']\n",
    "del df['lat']\n",
    "df['start_lon'] = df['lon']\n",
    "del df['lon']\n",
    "\n",
    "df = df.merge(df_stations, left_on='end_station_id', right_on='id')\n",
    "del df['id']\n",
    "df['end_lat'] = df['lat']\n",
    "del df['lat']\n",
    "df['end_lon'] = df['lon']\n",
    "del df['lon']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest distance: 0.0 km\n",
      "Greatest distance: 15.114165029636501 km\n"
     ]
    }
   ],
   "source": [
    "df[\"distance\"] = haversine(\n",
    "    df[\"start_lat\"],\n",
    "    df[\"start_lon\"],\n",
    "    df[\"end_lat\"],\n",
    "    df[\"end_lon\"],\n",
    ")\n",
    "\n",
    "print(f\"Smallest distance: {df['distance'].min()} km\")\n",
    "print(f\"Greatest distance: {df['distance'].max()} km\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate Speed to filter out unrealistic values. The maximum allowed speed of an ebike in the US is 20 mph, assuming the person has done no stops and as we are calculating the airline, these trips are almost certain to be faulty"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "df[\"speed\"] = df[\"distance\"] / df[\"duration\"].apply(\n",
    "    lambda duration: duration.total_seconds() / (60 * 60)\n",
    ")\n",
    "\n",
    "max_allowed_kmh = 20 * 1.60934 # 20mp/h in km/h\n",
    "\n",
    "df = df[df['speed'] < max_allowed_kmh]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "df['average_time'] = df['end_time'] - (df['duration'] / 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "#Because we have weather datapoints missing, we are merging to the nearest existing weather datapoint\n",
    "df_weather = pd.read_csv(\"../../data/weather_hourly_philadelphia_cleaned.parquet\")\n",
    "\n",
    "df_weather['date_time'] = pd.to_datetime(df_weather['date_time'])\n",
    "\n",
    "df_weather = df_weather.sort_values('date_time')\n",
    "\n",
    "df = df.sort_values('average_time')\n",
    "\n",
    "df_weather_and_trips = pd.merge_asof(df, df_weather, left_on='average_time', right_on='date_time', direction='nearest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "del df['average_time']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "df_weather_and_trips.to_parquet('../../data/bike_trips_cleaned.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}