{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78318c5a",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1be20ab",
   "metadata": {},
   "source": [
    "# TO DO: Explain and justify why you selected the three algorithms and describe their respective advantages and drawbacks. + How well do the models perform? Evaluate and benchmark your models’ performance using suitable evaluation metrics. Which model would you select for deployment? + How could the selected model be improved further? Explain some of the improvement levers that you might focus on in a follow-up project.\n",
    "– Evaluate your methodology and clearly state why you have opted for a specific approach in your analysis.\n",
    "– Relate your findings to the real world and interpret them for non-technical audiences (e.g. What do the coefficients in your regression model mean?, What does the achieved error mean for your model?, etc.)\n",
    "– Make sure to clearly state the implications (i.e. the ”so what?”) of your findings for managers/decision makers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d88398",
   "metadata": {},
   "source": [
    "We chose the random forest regression for our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480c1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "# from utils.evaluation import mean_average_percentage_error, root_mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a156ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_bike_trips_hourly = pd.read_parquet('../../data/bike_trips_hourly_FINAL.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c369a1d5",
   "metadata": {},
   "source": [
    "### Define X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc49f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bike_trips_hourly.drop(['starting_trips'], axis=1)\n",
    "y = df_bike_trips_hourly['starting_trips']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b42cb31",
   "metadata": {},
   "source": [
    "### Train the model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d334928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037598ea",
   "metadata": {},
   "source": [
    "We use a grid search to find the optimal combination of hyper-parameters\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74 :\n",
    "\n",
    "`max_features` = max number of features considered for splitting a node\n",
    "`min_samples_leaf` = min number of data points allowed in a leaf node\n",
    "`min_samples_split` = min number of data points placed in a node before the node is split\n",
    "`max_depth` = max number of levels in each decision tree\n",
    "`max_leaf_nodes` = max number of leaf nodes\n",
    "\n",
    "n_estimator is not used\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b25fb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestRegressor(n_estimators=100, bootstrap=True, random_state=42)\n",
    "param_grid = {\n",
    "\t'max_features': ['auto', 'sqrt', 'log2'],\n",
    "\t'min_samples_leaf': [1, 2, 4, 8],\n",
    "\t'min_samples_split': [2, 4, 8],\n",
    "\t'max_depth': [None, 5, 10, 50, 100],\n",
    "\t'max_leaf_nodes': [None, 10, 50, 100, 150],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933ce7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 5, 10, 50, 100],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'max_leaf_nodes': [None, 10, 50, 100, 150],\n",
       "                         'min_samples_leaf': [1, 2, 4, 8],\n",
       "                         'min_samples_split': [2, 4, 8]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GridSearchCV(\n",
    "    estimator, param_grid, cv=3, scoring=\"neg_mean_squared_error\", n_jobs=-1 , verbose=1\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "719c8784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 8}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40103f66",
   "metadata": {},
   "source": [
    "#### TO DO : We can see that ... depends on new values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd781ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893496a",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "It is generally not recommended to use the R^2 metric to evaluate the performance of a random forest model, because the R^2 metric is not well-suited for evaluating the performance of models that do not make predictions using a linear function. Instead, it is generally better to use error metrics that are more appropriate for non-linear models, such as mean squared error (MSE) or mean absolute error (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfdd0e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 16.07\n",
      "MSE: 677.48\n",
      "MAPE: 21.12%\n",
      "RMSE: 26.03\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MAPE: {(mean_absolute_error(y_test, y_pred) / y_test.mean()) * 100:.2f}%\")\n",
    "print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3612580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b69fa0ca125f7a75e8642045dca3cc5814dc978d434d8649da025a3b8baa816"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
